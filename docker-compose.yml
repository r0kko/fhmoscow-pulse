services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: app
    env_file:
      - .env
    ports:
      - "3000:3000"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - backend
    volumes:
      - .:/usr/src/app
      - /usr/src/app/node_modules
    labels:
      service: "api"
      env: "dev"

  client:
    build:
      context: ./client
      dockerfile: Dockerfile
      args:
        # Build-time base used by the bundle; keep relative to use proxy
        - VITE_API_BASE=/api
    container_name: client
    depends_on:
      - app
    ports:
      - "5173:4173"
    networks:
      - backend
    environment:
      # At runtime, point Vite proxy at the API service on the Docker network
      - VITE_API_PROXY_TARGET=http://app:3000
    labels:
      service: "client"
      env: "dev"

  db:
    image: postgres:17.6
    container_name: db
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
      POSTGRES_DB: ${DB_NAME}
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${DB_USER}", "-d", "${DB_NAME}"]
      interval: 5s
      retries: 5
    volumes:
      - db-data:/var/lib/postgresql/data
    networks:
      - backend
    restart: unless-stopped

  redis:
    image: redis:8.2.1
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - backend
    restart: unless-stopped

  dozzle:
    image: amir20/dozzle:latest
    container_name: dozzle
    ports:
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - backend
    restart: unless-stopped

  # Observability stack (runs with the project)
  loki:
    image: grafana/loki:2.9.8
    container_name: loki
    command: ["-config.file=/etc/loki/config.yml"]
    ports:
      - "3100:3100"
    networks:
      - backend
    volumes:
      - loki-data:/var/lib/loki
      - ./infra/observability/loki-config.yml:/etc/loki/config.yml:ro
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:3100/ready || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  promtail:
    image: grafana/promtail:2.9.8
    container_name: promtail
    command: ["-config.file=/etc/promtail/config.yml"]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./infra/observability/promtail-config.yml:/etc/promtail/config.yml:ro
      - promtail-data:/var/lib/promtail
    depends_on:
      - loki
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:9080/ready || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:v2.53.1
    container_name: prometheus
    ports:
      - "9090:9090"
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=30d"
      - "--storage.tsdb.wal-compression"
      - "--web.enable-lifecycle"
      - "--web.enable-remote-write-receiver"
    volumes:
      - ./infra/observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./infra/observability/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus-data:/prometheus
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:9090/-/ready || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./infra/observability/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:9093/-/ready || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  grafana:
    image: grafana/grafana:11.2.0
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_METRICS_ENABLED=true
      - GF_METRICS_DISABLE_TOTAL_STATS=true
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/var/lib/grafana/dashboards/pulse-app-overview.json
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana-data:/var/lib/grafana
      - ./infra/observability/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./infra/observability/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - loki
      - prometheus
      - alertmanager
      - tempo
    networks:
      - backend
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -qO- http://127.0.0.1:3000/api/health | grep -q '\\"database\\":\\"ok\\"'",
        ]
      interval: 30s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.52.0
    container_name: cadvisor
    ports:
      - "8081:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
    command:
      - '--docker_only=true'
      - '--housekeeping_interval=30s'
      - '--disable_metrics=advtcp,cpu_topology,cpuset,hugetlb,memory_numa,process,referenced_memory,resctrl,sched,tcp,udp,percpu,perf_event,pressure,diskIO'
      - '--store_container_labels=false'
      - '--whitelisted_container_labels=env,com.docker.compose.service,com.docker.compose.project'
      - '--event_storage_event_limit=default=0'
      - '--v=1'
    labels:
      service: "cadvisor"
      env: "dev"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - backend
    restart: unless-stopped

  node-exporter:
    image: prom/node-exporter:v1.8.2
    container_name: node-exporter
    pid: "host"
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($|/)'
    networks:
      - backend
    restart: unless-stopped

  tempo:
    image: grafana/tempo:2.5.0
    container_name: tempo
    command: ["-config.file=/etc/tempo.yaml"]
    ports:
      - "3200:3200"
    volumes:
      - ./infra/observability/tempo.yaml:/etc/tempo.yaml:ro
      - tempo-data:/var/lib/tempo
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://127.0.0.1:3200/status || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://${DB_USER}:${DB_PASS}@db:5432/${DB_NAME}?sslmode=disable
    ports:
      - "9187:9187"
    networks:
      - backend
    depends_on:
      - db
    restart: unless-stopped

  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter
    environment:
      - REDIS_ADDR=redis://redis:6379
    ports:
      - "9121:9121"
    networks:
      - backend
    depends_on:
      - redis
    restart: unless-stopped

  blackbox-exporter:
    image: prom/blackbox-exporter:latest
    container_name: blackbox-exporter
    ports:
      - "9115:9115"
    volumes:
      - ./infra/observability/blackbox.yml:/etc/blackbox_exporter/config.yml:ro
    networks:
      - backend
    restart: unless-stopped

volumes:
  db-data:
  grafana-data:
  prometheus-data:
  loki-data:
  promtail-data:
  tempo-data:

networks:
  backend:
    driver: bridge
